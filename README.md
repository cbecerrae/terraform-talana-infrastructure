# Terraform Infrastructure for Talana Attendance Marking

This repository provisions and manages the AWS infrastructure using **Terraform** to automate attendance marking in [Talana](https://peru.talana.com/es/remuneraciones/) using ECS tasks, EventBridge Scheduler, and CI/CD pipelines. The solution includes a variety of AWS resources for building, deploying, and managing the scraper bot, as well as scheduling its tasks and handling alerts.

## Resources Managed by Terraform

This Terraform configuration implements the cloud environment for running the attendance marking process in Talana by creating and managing the necessary AWS resources efficiently. Designed for seamless integration with GitHub, it enables automatic image builds and deployments whenever changes are pushed to the `main` branch of the [Talana Scraper Bot repository](https://github.com/cbecerrae/talana-scraper-bot).

### Provisioned Resources

| **AWS Resources** | **Terraform Resource Type** | **Description** |
|-------------------|-----------------------------|-----------------|
| **CodeBuild Project** | `aws_codebuild_project` | Project to build the Docker image for the scraper bot. |
| **CodePipeline** | `aws_codepipeline` | Pipeline to automate the CI/CD process for building and deploying the scraper bot. |
| **ECR Repository** | `aws_ecr_repository` | Repository to store the Docker images used by ECS tasks. |
| **ECS Cluster** | `aws_ecs_cluster` <br> `aws_ecs_cluster_capacity_providers` | The cluster where ECS tasks run, configured with the FARGATE capacity provider. |
| **ECS Task Definition** | `aws_ecs_task_definition` | The task definition for the scraper bot container. |
| **EventBridge Schedulers** | `aws_scheduler_schedule` | Schedules to run ECS tasks at specific intervals based on provided cron expressions, created from the `eventbridge_scheduler` custom-built module. |
| **IAM Policies** | `aws_iam_role_policy` | Policies attached to IAM roles. |
| **IAM Roles** | `aws_iam_role` | Roles for ECS task execution, EventBridge scheduler, CodeBuild, and CodePipeline. |
| **S3 Buckets** | `aws_s3_bucket` | Buckets for storing objects generated by ECS tasks and pipeline artifacts. |
| **Security Group** | `aws_security_group` | Security Group for running ECS tasks. |
| **SNS Topic and Subscription** | `aws_sns_topic` <br> `aws_sns_topic_subscription` | Topic for sending error alerts from ECS tasks and the subscribed endpoint to receive them. |
| **VPC and Networking** | `aws_default_network_acl` <br> `aws_default_route_table` <br> `aws_default_security_group` <br> `aws_internet_gateway` <br> `aws_route` <br> `aws_route_table` <br> `aws_route_table_association` <br> `aws_subnet` <br> `aws_vpc ` | VPC with public subnets, internet gateway, security group, route table, and default network ACL, all created from the `module.vpc`. |

### Data Resources  

| **AWS Resources** | **Terraform Resource Type** | **Description** |
|-------------------|------------------------|-----------------|
| **Availability Zones** | `data.aws_availability_zones` | Retrieves availability zones for resource placement. |
| **Caller Identity** | `data.aws_caller_identity` | Retrieves the AWS account identity. |
| **CodeStar Connection** | `data.aws_codestarconnections_connection` | Establishes a connection between GitHub and AWS for CI/CD. |
| **Trust Policies** | `data.aws_iam_policy_document` | Trust policies for IAM roles. |

### Providers

| **Provider** | **Source** | **Version** | **Description** |
|--------------|------------|-------------|-----------------|
| `aws`| `hashicorp/aws` | `~> 5.84.0` | AWS provider used to manage AWS resources. |

### Modules

| **Module** | **Source** | **Description** |
|------------|------------|----------------|
| `vpc`  | `terraform-aws-modules/vpc/aws` | Module to create a VPC and associated networking resources. |
| `eventbridge_scheduler` | `./modules/eventbridge-scheduler`| Custom-built module for scheduling ECS tasks with EventBridge Scheduler. |

## Pre-requisites

Some resources need to be created manually before deploying this solution with `terraform apply`. In the **[Usage](#usage)** section, you'll find instructions on how to manually create the following prerequisite resources:

- **AWS Account**: An active AWS account with the necessary permissions.
- **AWS Credentials**: AWS access keys with sufficient permissions to deploy and configure the resources mentioned.
- **AWS CodeStar Connection**: To connect an AWS account with GitHub for access to a fork of the [Talana Scraper Bot repository](https://github.com/cbecerrae/talana-scraper-bot).
- **S3 Bucket**: For storing Terraform state, if using an S3 backend for Terraform.
- **DynamoDB Table**: For managing state locks in Terraform, if using an S3 backend.

These resources must be set up first to ensure proper functionality during deployment.

## Usage  

### 1. Clone the Repository 

```bash
git clone https://github.com/cbecerrae/terraform-talana-infrastructure.git
cd terraform-talana-infrastructure
```  

### 2. Configure AWS Credentials 

Ensure your AWS credentials are properly configured using one of the following methods:  

- **AWS CLI**:  
   ```bash
   aws configure
   ```  
- **Environment variables**:  
   ```bash
   export AWS_ACCESS_KEY_ID="your-access-key"
   export AWS_SECRET_ACCESS_KEY="your-secret-key"
   ```  
- **HCP Terraform**:  
   If you're using HashiCorp Cloud Platform (HCP) Terraform, you should configure your AWS credentials as part of a variable set of environment-type variables within the HCP platform to securely manage and store sensitive information like AWS access keys. Ensure you create and reference the appropriate environment variable set in the HCP workspace for your AWS credentials.

### 3. Initialize Terraform  

By default, this repository is configured to use an **Amazon S3 backend** to store the Terraform state. However, you can switch to **HCP Terraform** or **Local Backend** by commenting/uncommenting the relevant blocks in `terraform.tf`.  

#### S3 Backend  

The backend stores the Terraform state in an **Amazon S3 bucket** and uses DynamoDB for state locking.  

1. **Ensure the S3 Bucket and DynamoDB Table Exist:**  
   - **S3 Bucket:** `terraform-talana-automation-terraform-state`  
   - **DynamoDB Table:** `terraform-talana-automation-terraform-state-locks`  

   If they are not created, follow these steps:  

   - **Create the S3 Bucket:**  
     - Go to **[AWS S3 Console](https://s3.console.aws.amazon.com/s3/home)**  
     - Click **"Create bucket"**  
     - Name it: `terraform-talana-automation-terraform-state` (alter the name to ensure it is unique across all AWS accounts)
     - Select a **region** (e.g., `us-east-1`)  
     - Enable **versioning**  
     - Click **"Create bucket"**  

   - **Create the DynamoDB Table:**  
     - Go to **[AWS DynamoDB Console](https://console.aws.amazon.com/dynamodb/home)**  
     - Click **"Create table"**  
     - Name it: `terraform-talana-automation-terraform-state-locks`  
     - **Partition key:** `LockID` (Type: `String`)  
     - **Capacity mode:** On-demand  
     - Click **"Create table"**  
  
   Don't forget to manually tag both resources with the tags **owner** and **project**. 

2. **Verify the Terraform Backend Configuration (`terraform.tf`)**  

```hcl
terraform {
  backend "s3" {
    bucket         = "terraform-talana-automation-terraform-state"
    key            = "state/terraform.tfstate"
    region         = "us-east-1"
    dynamodb_table = "terraform-talana-automation-terraform-state-locks"
  }
}
```  

#### HCP Terraform  

If you prefer to use **HCP Terraform**, comment out the **S3 backend block** in `terraform.tf` and uncomment the **cloud block**:  

```hcl
cloud {
  organization = "your-organization-name"
  workspaces {
    name = "your-workspace-name"
  }
}
```  

#### Local Backend  

If you prefer to keep the Terraform state locally, comment out both **S3** and **cloud** backend blocks in `terraform.tf`. Terraform will then store the `terraform.tfstate` file in the local project directory.  

### 4. Initialize Terraform  

Once the backend is configured, run the following command:  

```bash
terraform init
```  

### 5. Create an AWS CodeStar Connection  

To integrate your **forked repository** with AWS services, you need to create an **AWS CodeStar Connection** that authorizes access to your fork of the [Talana Scraper Bot repository](https://github.com/cbecerrae/talana-scraper-bot). Follow these steps:  

#### 1. Fork the Talana Scraper Bot Repository  
- Go to the [Talana Scraper Bot repository](https://github.com/cbecerrae/talana-scraper-bot) on GitHub.  
- Click **"Fork"** to create a copy in your GitHub account.  

#### 2. Create a CodeStar Connection in AWS  
- Open the **[AWS CodeStar Connections Console](https://us-east-1.console.aws.amazon.com/codesuite/settings/connections)**.  
- Click **"Create connection"**.  
- Set a name (e.g., `<GitHub-username>-connection`).  
- Choose **GitHub** as the provider.  
- Select an existing **GitHub App** or install a new one to authorize the connection between GitHub and AWS.  

#### 3. Grant Access to the Forked Repository  
- Go to **[GitHub Application Settings](https://github.com/settings/installations)**.  
- Find **"AWS Connector for GitHub"** and ensure it has access to your **forked repository**.  

Once completed, the connection will allow AWS services to interact with your forked repository.

### 6. Configure Variables  

Before setting up the variables in a `terraform.tfvars` file, carefully review the **[Input Variables](#input-variables)** section to understand the required and optional variables. Check the `variables.tf` file for more details and to customize optional variables.

Create a `terraform.tfvars` file in the root directory of your Terraform project to define the values for the variables used in your configuration.

If you are using **HCP Terraform** as the backend, you can define variables directly in the **workspace settings** by navigating to **"Variables"** in your workspace on **[HCP Terraform Workspaces](https://app.terraform.io/app/workspaces)**. These variables take precedence over `terraform.tfvars` when running in the cloud.

### 7. Apply the Terraform Configuration 

To deploy all the resources in the terraform configuration, run the following Terraform command:

```bash
terraform apply
```  

Review the plan and confirm the deployment by typing `yes` when prompted.  

### 8. Clean-up  

To remove the created resources, run the following Terraform command:  

```bash
terraform destroy
```

Review the destroy plan and confirm the destruction by typing `yes` when prompted. 

After the destroy has finished, optionally delete the resources created manually in the previous steps, such as the AWS CodeStar Connection, S3 bucket for Terraform state, and DynamoDB table for state locks.

## Input Variables

### Required Variables  

These variables must be provided when initializing the Terraform configuration. Make sure to review their values carefully before applying changes.  

| Name | Type | Description | Required |
|------|------|-------------|----------|
| `aws_codestarconnections_connection_name` | `string` | Connection name of the AWS CodeStar Connections connection. | Yes |
| `subscription_email` | `string` | Email to subscribe to the SNS topic. | Yes |
| `tags` | `map(string)` | Tags for AWS resources (`owner` and `project` tags are required). | Yes |
| `talana_credentials` | `object` | Talana credentials to pass to the ECS task (`user_email`, `user_password`). **Sensitive**. | Yes |
| `talana_scraper_bot_repository_id` | `string` | ID of the Talana Scraper Bot repository authorized in the AWS CodeStar Connections connection (`owner/repository_name`). | Yes | 

Some of these required variables contain sensitive data. Ensure that they are **not committed** to the forked repository or exposed in any way.

### Optional Variables  

These variables have default values and can be overridden as needed. Adjust them based on your requirements. You will particularly want to change `mark_schedules` and `schedule_expression_timezone` as their default values are mainly for reference only.

| Name | Type | Description | Default Value |
|------|------|-------------|--------------|
| `aws_region` | `string` | AWS region in which to provision infrastructure. | `"us-east-1"` |
| `mark_schedules` | `list(object)` | Schedules to trigger the ECS tasks. Each object contains `mark_type`, `schedule_name_suffix`, `schedule_expression`, and `schedule_description`. | Refer to `variables.tf` |
| `project_name` | `string` | Name of the project. Must not exceed 30 characters. | `"terraform-talana-automation"` |
| `schedule_expression_timezone` | `string` | Timezone for the schedule expression. | `"America/Lima"` |
| `talana_scraper_bot_repository_branch` | `string` | Branch of the Talana Scraper Bot forked repository authorized in the AWS CodeStar Connections connection. | `"main"` | 

You may change these **optional variables** default values directly in `variables.tf` and push them to your forked repository, as they are **not sensitive** at all.

## Estimated Cost

The estimated cost of this solution, when deployed, **should not exceed $1.00 USD per month** in your AWS account bill, specifically in the us-east-1 (N. Virginia) region, if you configure EventBridge Scheduler to run the ECS tasks twice a day (for typical 'In' and 'Out' attendance marking).

## GitHub Actions

[![Terraform Plan and Apply with Manual Approval](https://github.com/cbecerrae/terraform-talana-infrastructure/actions/workflows/terraform-plan-and-apply.yml/badge.svg)](https://github.com/cbecerrae/terraform-talana-infrastructure/actions/workflows/terraform-plan-and-apply.yml)

In the [`.github/workflows/terraform-plan-and-apply.yml`](.github/workflows/terraform-plan-and-apply.yml) file, you'll find the "Terraform Plan and Apply with Manual Approval" workflow, which implements CI/CD for changes pushed to the `main` branch, excluding updates to markdown files (`.md`) or GitHub Actions files within `.github/`. This workflow can also be triggered manually and has a concurrency limit of 1, with in-progress jobs being canceled if a new job is triggered. 

The CI/CD pipeline consists of a `plan` job that runs `terraform plan` and stores the `tfplan` as an artifact, which is then passed to the `apply` job. The `apply` job is configured within a ***production*** environment that has **Required Reviewers** enabled to ensure the generated plan is reviewed as part of the manual approval process before executing `terraform apply`.

You can disable this workflow, but if you have forked this repository and want to use it, follow these setup steps:

- Create a ***production*** environment in your fork, and enable the environment protection rule for required reviewers.
- Configure the following repository secrets in GitHub Secrets:
   - **AWS_ACCESS_KEY_ID**: AWS access key.
   - **AWS_SECRET_ACCESS_KEY**: AWS secret access key.
   - **TERRAFORM_TFVARS**: Content of `terraform.tfvars`.